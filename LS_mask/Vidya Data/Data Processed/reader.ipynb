{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing all 0 and below 0 values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "import numpy as np\n",
    "\n",
    "def process_geotiff(input_file, output_file):\n",
    "    # Open the input TIFF file\n",
    "    with rasterio.open(input_file) as src:\n",
    "        # Read the data from the first band\n",
    "        data = src.read(1)\n",
    "        \n",
    "        # Set negative and zero values to NaN\n",
    "        data[data <= 0] = np.nan\n",
    "        \n",
    "        # Update the metadata to handle NaN values correctly\n",
    "        profile = src.profile\n",
    "        profile.update(\n",
    "            dtype=rasterio.float32,  # Ensure data type can handle NaN\n",
    "            nodata=np.nan            # Define nodata value\n",
    "        )\n",
    "        \n",
    "        # Write the modified data to a new TIFF file\n",
    "        with rasterio.open(output_file, 'w', **profile) as dst:\n",
    "            dst.write(data, 1)\n",
    "\n",
    "# Define input and output file paths\n",
    "input_file = 'UK_DEM_merged.tif'\n",
    "output_file = 'UK_DEM2.tif'\n",
    "\n",
    "# Process the TIFF file\n",
    "process_geotiff(input_file, output_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the diffrence in both the areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The difference raster has been created and saved.\n"
     ]
    }
   ],
   "source": [
    "import rasterio\n",
    "from rasterio.enums import Resampling\n",
    "from rasterio.warp import reproject\n",
    "import numpy as np\n",
    "\n",
    "# Paths to the input GeoTIFF files\n",
    "raster1_path = 'UK_DEM.tif'\n",
    "raster2_path = 'UK_temp.tif'\n",
    "output_path = 'UK_imputation_raster_mergedDEM.tif'\n",
    "\n",
    "# Function to create a binary mask where data is present\n",
    "def create_presence_mask(data, nodata_value):\n",
    "    mask = np.ones_like(data, dtype=np.uint8)\n",
    "    if nodata_value is not None and np.isnan(nodata_value):\n",
    "        mask[np.isnan(data)] = 0\n",
    "    elif nodata_value is not None:\n",
    "        mask[data == nodata_value] = 0\n",
    "    return mask\n",
    "\n",
    "# Open the input rasters\n",
    "with rasterio.open(raster1_path) as src1:\n",
    "    data1 = src1.read(1)\n",
    "    meta1 = src1.meta\n",
    "    nodata1 = src1.nodata\n",
    "\n",
    "with rasterio.open(raster2_path) as src2:\n",
    "    data2 = src2.read(1)\n",
    "    nodata2 = src2.nodata\n",
    "\n",
    "    # Resample raster2 to match raster1 if dimensions differ\n",
    "    if src1.shape != src2.shape:\n",
    "       \n",
    "        data2_resampled = np.empty(src1.shape, dtype=np.float32)\n",
    "        reproject(\n",
    "            source=data2,\n",
    "            destination=data2_resampled,\n",
    "            src_transform=src2.transform,\n",
    "            src_crs=src2.crs,\n",
    "            dst_transform=src1.transform,\n",
    "            dst_crs=src1.crs,\n",
    "            resampling=Resampling.bilinear\n",
    "        )\n",
    "    else:\n",
    "        data2_resampled = data2\n",
    "\n",
    "# Create presence masks for each raster\n",
    "mask1 = create_presence_mask(data1, nodata1)\n",
    "mask2 = create_presence_mask(data2_resampled, nodata2)\n",
    "\n",
    "# Calculate the difference mask\n",
    "difference_mask = mask1 & ~mask2\n",
    "\n",
    "# Update metadata for the output raster\n",
    "meta1.update(dtype=rasterio.uint8, nodata=0)\n",
    "\n",
    "# Save the difference mask as a new GeoTIFF file\n",
    "with rasterio.open(output_path, 'w', **meta1) as dst:\n",
    "    dst.write(difference_mask, 1)\n",
    "\n",
    "print(\"The difference raster has been created and saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resampling the Imputation raster to pixel size of temprature raster "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "from rasterio.enums import Resampling\n",
    "import numpy as np\n",
    "\n",
    "# Paths to the input GeoTIFF files\n",
    "raster1_path = 'UK_temp.tif'  # This is the reference raster for resolution\n",
    "raster2_path = 'UK_imputation_raster.tif'\n",
    "output_path = 'UK_imputation_resampled.tif'\n",
    "\n",
    "# Function to create a binary mask where data is present\n",
    "def create_presence_mask(data, nodata_value):\n",
    "    mask = np.ones_like(data, dtype=np.uint8)\n",
    "    if nodata_value is not None and np.isnan(nodata_value):\n",
    "        mask[np.isnan(data)] = 0\n",
    "    elif nodata_value is not None:\n",
    "        mask[data == nodata_value] = 0\n",
    "    return mask\n",
    "\n",
    "# Open the reference raster to get its metadata and resolution\n",
    "with rasterio.open(raster1_path) as src_ref:\n",
    "    # Read the data from the first band\n",
    "    data_ref = src_ref.read(1)\n",
    "    profile_ref = src_ref.profile\n",
    "    transform_ref = src_ref.transform  # Get the transform for resampling\n",
    "\n",
    "# Open the raster to be resampled\n",
    "with rasterio.open(raster2_path) as src:\n",
    "    # Read the data from the first band\n",
    "    data = src.read(1)\n",
    "    profile = src.profile\n",
    "\n",
    "    # Resample raster2 to match raster1 if dimensions differ\n",
    "    if src_ref.shape != src.shape:\n",
    "        resampled_data = np.empty(src_ref.shape, dtype=np.float32)\n",
    "        rasterio.warp.reproject(\n",
    "            source=rasterio.band(src, 1),\n",
    "            destination=resampled_data,\n",
    "            src_transform=src.transform,\n",
    "            src_crs=src.crs,\n",
    "            dst_transform=transform_ref,\n",
    "            dst_crs=profile_ref['crs'],\n",
    "            resampling=Resampling.bilinear\n",
    "        )\n",
    "    else:\n",
    "        resampled_data = data  # No need to resample if already matching\n",
    "\n",
    "# Create a presence mask for the resampled raster\n",
    "mask_resampled = create_presence_mask(resampled_data, src.nodata)\n",
    "\n",
    "# Update metadata for the output raster\n",
    "profile_ref.update(\n",
    "    dtype=rasterio.uint8,  # Update data type if necessary\n",
    "    nodata=0  # Define nodata value\n",
    ")\n",
    "\n",
    "# Save the resampled mask as a new GeoTIFF file\n",
    "with rasterio.open(output_path, 'w', **profile_ref) as dst:\n",
    "    dst.write(mask_resampled, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New Section from here "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapefile saved successfully: UK_imputation2.shp\n"
     ]
    }
   ],
   "source": [
    "import rasterio\n",
    "from shapely.geometry import Point\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "\n",
    "# Path to your GeoTIFF file\n",
    "input_file = 'UK_imputation_resampled2.tif'\n",
    "\n",
    "# Lists to store point geometries, coordinates, and pixel values\n",
    "points = []\n",
    "lats = []\n",
    "lons = []\n",
    "values = []\n",
    "\n",
    "# Open the GeoTIFF file\n",
    "with rasterio.open(input_file) as src:\n",
    "    # Get the number of rows and columns in the raster\n",
    "    rows, cols = src.shape\n",
    "    \n",
    "    # Get the nodata value\n",
    "    nodata_value = src.nodata\n",
    "\n",
    "    # Read the entire raster data into memory\n",
    "    data = src.read(1)\n",
    "\n",
    "    # Iterate through each pixel in the raster\n",
    "    for row in range(rows):\n",
    "        for col in range(cols):\n",
    "            # Read pixel value\n",
    "            pixel_value = data[row, col]\n",
    "            \n",
    "            # Check if pixel value is not nodata and not NaN\n",
    "            if pixel_value != nodata_value and not np.isnan(pixel_value):\n",
    "                # Convert pixel coordinates to geographic coordinates (longitude, latitude)\n",
    "                lon, lat = src.xy(row, col)\n",
    "\n",
    "                # Create a point geometry for each valid pixel coordinate\n",
    "                point = Point(lon, lat)\n",
    "                points.append(point)\n",
    "                lats.append(lat)\n",
    "                lons.append(lon)\n",
    "                values.append(pixel_value)\n",
    "\n",
    "# Create a GeoDataFrame from the list of points\n",
    "gdf = gpd.GeoDataFrame(geometry=points, crs=src.crs)\n",
    "\n",
    "# Add latitude, longitude, and pixel values to the GeoDataFrame\n",
    "gdf['latitude'] = lats\n",
    "gdf['longitude'] = lons\n",
    "gdf['value'] = values\n",
    "\n",
    "# Save the GeoDataFrame as a shapefile\n",
    "output_shapefile = 'UK_imputation2.shp'\n",
    "gdf.to_file(output_shapefile)\n",
    "\n",
    "print(f\"Shapefile saved successfully: {output_shapefile}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered shapefile saved successfully: UK_imputation.shp\n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "\n",
    "# Paths to your shapefiles\n",
    "file1_path = 'UK_imputation.shp'\n",
    "file2_path = 'UK_temp.shp'\n",
    "output_path = 'UK_imputation.shp'\n",
    "\n",
    "# Load the shapefiles\n",
    "gdf1 = gpd.read_file(file1_path)\n",
    "gdf2 = gpd.read_file(file2_path)\n",
    "\n",
    "# Ensure both GeoDataFrames have the same CRS\n",
    "if gdf1.crs != gdf2.crs:\n",
    "    gdf2 = gdf2.to_crs(gdf1.crs)\n",
    "\n",
    "# Identify points in gdf1 that are not in gdf2 based on latitude and longitude\n",
    "gdf1_filtered = gdf1[~gdf1.apply(lambda x: (x['latitude'], x['longitude']) in \n",
    "                                set(gdf2.apply(lambda y: (y['latitude'], y['longitude']), axis=1)), axis=1)]\n",
    "\n",
    "# Save the filtered GeoDataFrame to a new shapefile\n",
    "gdf1_filtered.to_file(output_path)\n",
    "\n",
    "print(f\"Filtered shapefile saved successfully: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Genrate another resample mask from diffrence and apply it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "from shapely.geometry import Point\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "\n",
    "# Path to your GeoTIFF file\n",
    "input_file = 'UK_imputation_resampled2.tif'\n",
    "\n",
    "# Lists to store point geometries, coordinates, and pixel values\n",
    "points = []\n",
    "lats = []\n",
    "lons = []\n",
    "values = []\n",
    "\n",
    "# Open the GeoTIFF file\n",
    "with rasterio.open(input_file) as src:\n",
    "    # Get the number of rows and columns in the raster\n",
    "    rows, cols = src.shape\n",
    "    \n",
    "    # Get the nodata value\n",
    "    nodata_value = src.nodata\n",
    "\n",
    "    # Read the entire raster data into memory\n",
    "    data = src.read(1)\n",
    "\n",
    "    # Iterate through each pixel in the raster\n",
    "    for row in range(rows):\n",
    "        for col in range(cols):\n",
    "            # Read pixel value\n",
    "            pixel_value = data[row, col]\n",
    "            \n",
    "            # Check if pixel value is not nodata and not NaN\n",
    "            if pixel_value != nodata_value and not np.isnan(pixel_value):\n",
    "                # Convert pixel coordinates to geographic coordinates (longitude, latitude)\n",
    "                lon, lat = src.xy(row, col)\n",
    "\n",
    "                # Create a point geometry for each valid pixel coordinate\n",
    "                point = Point(lon, lat)\n",
    "                points.append(point)\n",
    "                lats.append(lat)\n",
    "                lons.append(lon)\n",
    "                values.append(pixel_value)\n",
    "\n",
    "# Create a GeoDataFrame from the list of points\n",
    "gdf = gpd.GeoDataFrame(geometry=points, crs=src.crs)\n",
    "\n",
    "# Add latitude, longitude, and pixel values to the GeoDataFrame\n",
    "gdf['latitude'] = lats\n",
    "gdf['longitude'] = lons\n",
    "gdf['value'] = values\n",
    "\n",
    "# Save the GeoDataFrame as a shapefile\n",
    "output_shapefile = 'UK_imputation2.shp'\n",
    "gdf.to_file(output_shapefile)\n",
    "\n",
    "print(f\"Shapefile saved successfully: {output_shapefile}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered shapefile saved successfully: UK_imputation_points2.shp\n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "\n",
    "# Paths to your shapefiles\n",
    "file1_path = 'UK_imputation2.shp'\n",
    "file2_path = 'UK_temp.shp'\n",
    "file3_path = 'UK_imputation.shp'  # Path to the third shapefile\n",
    "output_path = 'UK_imputation_points2.shp'  # Ensure this is a new output file name\n",
    "\n",
    "# Load the shapefiles\n",
    "gdf1 = gpd.read_file(file1_path)\n",
    "gdf2 = gpd.read_file(file2_path)\n",
    "gdf3 = gpd.read_file(file3_path)\n",
    "\n",
    "# Ensure all GeoDataFrames have the same CRS\n",
    "if gdf1.crs != gdf2.crs:\n",
    "    gdf2 = gdf2.to_crs(gdf1.crs)\n",
    "if gdf1.crs != gdf3.crs:\n",
    "    gdf3 = gdf3.to_crs(gdf1.crs)\n",
    "\n",
    "# Create sets of (latitude, longitude) tuples for gdf2 and gdf3\n",
    "set_gdf2 = set(gdf2.apply(lambda y: (y['latitude'], y['longitude']), axis=1))\n",
    "set_gdf3 = set(gdf3.apply(lambda y: (y['latitude'], y['longitude']), axis=1))\n",
    "\n",
    "# Combine the sets\n",
    "combined_set = set_gdf2.union(set_gdf3)\n",
    "\n",
    "# Identify points in gdf1 that are not in either gdf2 or gdf3\n",
    "gdf1_filtered = gdf1[~gdf1.apply(lambda x: (x['latitude'], x['longitude']) in combined_set, axis=1)]\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combnine points from your and other resample mask "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final merged shapefile saved successfully: final_points.shp\n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "\n",
    "final_output_path = 'final_points.shp'  # Path for the final merged shapefile\n",
    "\n",
    "# Load the filtered shapefile and the third shapefile\n",
    "filtered_points = gpd.read_file(output_path)\n",
    "imputation_points = gpd.read_file(file3_path)\n",
    "\n",
    "# Merge the two GeoDataFrames using pandas.concat\n",
    "final_points = gpd.GeoDataFrame(pd.concat([filtered_points, imputation_points], ignore_index=True))\n",
    "\n",
    "# Ensure the final GeoDataFrame has the same CRS\n",
    "final_points = final_points.set_crs(gdf1.crs)\n",
    "\n",
    "# Save the merged GeoDataFrame to a new shapefile\n",
    "final_points.to_file(final_output_path)\n",
    "\n",
    "print(f\"Final merged shapefile saved successfully: {final_output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VIBBAT\\AppData\\Local\\Temp\\ipykernel_9240\\3791987192.py:29: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
      "  missing_points.to_file('UK_imputed_KNN.shp')\n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "\n",
    "# Load shapefiles\n",
    "missing_points = gpd.read_file('UK_imputation.shp')\n",
    "complete_data = gpd.read_file('UK_temp.shp')\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from shapely.geometry import Point\n",
    "\n",
    "# Convert GeoDataFrame to DataFrame for KNN processing\n",
    "X_known = complete_data[['latitude', 'longitude']]\n",
    "y_known = complete_data['value']\n",
    "X_missing = missing_points[['latitude', 'longitude']]\n",
    "\n",
    "\n",
    "# Initialize KNN regressor\n",
    "knn = KNeighborsRegressor(n_neighbors=3, weights='distance')\n",
    "\n",
    "# Fit KNN model\n",
    "knn.fit(X_known, y_known)\n",
    "\n",
    "# Predict missing temperatures\n",
    "imputed_temperatures = knn.predict(X_missing)\n",
    "\n",
    "# Add imputed temperatures to missing_points GeoDataFrame\n",
    "missing_points['temperature'] = imputed_temperatures\n",
    "\n",
    "# Save GeoDataFrame to shapefile\n",
    "missing_points.to_file('UK_imputed_KNN.shp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Idea \n",
    "\n",
    "1) So first we check how many 30m points are there around a 12km2 point\n",
    "2) Next we have lat and long of each thing so find distances using that lat and long\n",
    "3) Find some relation between elevation and temprature value \n",
    "\n",
    "\n",
    "Basic Idea need to do a lot of other changes\n",
    "\n",
    "Need to Do \n",
    "1) Check resampling algos \n",
    "2) Check imputation algos \n",
    "3) Check about KNN (elbow rule)\n",
    "3) explore more into using DEM while doing imputation \n",
    "4) the observed dataset I was checking mostly doesn't have points on the areas where we are conducting imputation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
