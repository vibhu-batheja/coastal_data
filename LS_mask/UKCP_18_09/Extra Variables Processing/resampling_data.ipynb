{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing 0 Values from DEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "import numpy as np\n",
    "\n",
    "def process_geotiff(input_file, output_file):\n",
    "    # Open the input TIFF file\n",
    "    with rasterio.open(input_file) as src:\n",
    "        # Read the data from the first band\n",
    "        data = src.read(1)\n",
    "        \n",
    "        # Set negative and zero values to NaN\n",
    "        data[data == 0] = np.nan\n",
    "        \n",
    "        # Update the metadata to handle NaN values correctly\n",
    "        profile = src.profile\n",
    "        profile.update(\n",
    "            dtype=rasterio.float32,  # Ensure data type can handle NaN\n",
    "            nodata=np.nan            # Define nodata value\n",
    "        )\n",
    "        \n",
    "        # Write the modified data to a new TIFF file\n",
    "        with rasterio.open(output_file, 'w', **profile) as dst:\n",
    "            dst.write(data, 1)\n",
    "\n",
    "# Define input and output file paths\n",
    "input_file = 'UK_DEM_merged_larger_ext.tif'\n",
    "output_file = 'UK_DEM2.tif'\n",
    "\n",
    "# Process the TIFF file\n",
    "process_geotiff(input_file, output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Resmapling Libraries to do it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Resampling Methods:  14%|█▍        | 2/14 [00:00<00:01,  7.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The final raster with NaN values for zero data using nearest has been created and saved.\n",
      "The final raster with NaN values for zero data using bilinear has been created and saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Resampling Methods:  29%|██▊       | 4/14 [00:00<00:01,  5.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The final raster with NaN values for zero data using cubic has been created and saved.\n",
      "The final raster with NaN values for zero data using cubic_spline has been created and saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Resampling Methods:  43%|████▎     | 6/14 [00:01<00:01,  5.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The final raster with NaN values for zero data using lanczos has been created and saved.\n",
      "The final raster with NaN values for zero data using average has been created and saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Resampling Methods:  57%|█████▋    | 8/14 [00:01<00:01,  5.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The final raster with NaN values for zero data using mode has been created and saved.\n",
      "The final raster with NaN values for zero data using max has been created and saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Resampling Methods:  71%|███████▏  | 10/14 [00:01<00:00,  5.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The final raster with NaN values for zero data using min has been created and saved.\n",
      "The final raster with NaN values for zero data using med has been created and saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Resampling Methods:  86%|████████▌ | 12/14 [00:02<00:00,  5.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The final raster with NaN values for zero data using q1 has been created and saved.\n",
      "The final raster with NaN values for zero data using q3 has been created and saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Resampling Methods: 100%|██████████| 14/14 [00:03<00:00,  4.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The final raster with NaN values for zero data using sum has been created and saved.\n",
      "The final raster with NaN values for zero data using rms has been created and saved.\n",
      "List of all processed file paths:\n",
      "manual_method_resampling\\nearest\\UK_imputation_resampled_12km_nearest_processed.tif\n",
      "manual_method_resampling\\bilinear\\UK_imputation_resampled_12km_bilinear_processed.tif\n",
      "manual_method_resampling\\cubic\\UK_imputation_resampled_12km_cubic_processed.tif\n",
      "manual_method_resampling\\cubic_spline\\UK_imputation_resampled_12km_cubic_spline_processed.tif\n",
      "manual_method_resampling\\lanczos\\UK_imputation_resampled_12km_lanczos_processed.tif\n",
      "manual_method_resampling\\average\\UK_imputation_resampled_12km_average_processed.tif\n",
      "manual_method_resampling\\mode\\UK_imputation_resampled_12km_mode_processed.tif\n",
      "manual_method_resampling\\max\\UK_imputation_resampled_12km_max_processed.tif\n",
      "manual_method_resampling\\min\\UK_imputation_resampled_12km_min_processed.tif\n",
      "manual_method_resampling\\med\\UK_imputation_resampled_12km_med_processed.tif\n",
      "manual_method_resampling\\q1\\UK_imputation_resampled_12km_q1_processed.tif\n",
      "manual_method_resampling\\q3\\UK_imputation_resampled_12km_q3_processed.tif\n",
      "manual_method_resampling\\sum\\UK_imputation_resampled_12km_sum_processed.tif\n",
      "manual_method_resampling\\rms\\UK_imputation_resampled_12km_rms_processed.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import rasterio\n",
    "from rasterio.enums import Resampling\n",
    "from rasterio.warp import reproject, Resampling as WarpResampling\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define the resampling methods\n",
    "resampling_methods = [\n",
    "    WarpResampling.nearest,\n",
    "    WarpResampling.bilinear,\n",
    "    WarpResampling.cubic,\n",
    "    WarpResampling.cubic_spline,\n",
    "    WarpResampling.lanczos,\n",
    "    WarpResampling.average,\n",
    "    WarpResampling.mode,\n",
    "    WarpResampling.max,\n",
    "    WarpResampling.min,\n",
    "    WarpResampling.med,\n",
    "    WarpResampling.q1,\n",
    "    WarpResampling.q3,\n",
    "    WarpResampling.sum,\n",
    "    WarpResampling.rms\n",
    "]\n",
    "\n",
    "# Paths to the input GeoTIFF files\n",
    "raster1_path = 'ppt_1980-2010.tif'  # This is the reference raster for resolution\n",
    "raster2_path = 'UK_DEM2.tif'\n",
    "\n",
    "# Main directory for storing the processed files\n",
    "main_dir = 'manual_method_resampling'\n",
    "os.makedirs(main_dir, exist_ok=True)\n",
    "\n",
    "# List to store paths of all processed files\n",
    "processed_file_paths = []\n",
    "\n",
    "# Function to process the GeoTIFF to set zero values to NaN\n",
    "def process_geotiff(data, profile, output_file):\n",
    "    data[data == 0] = np.nan\n",
    "    profile.update(dtype=rasterio.float32, nodata=np.nan)\n",
    "    with rasterio.open(output_file, 'w', **profile) as dst:\n",
    "        dst.write(data, 1)\n",
    "\n",
    "# Loop through each resampling method with a progress bar\n",
    "for method in tqdm(resampling_methods, desc=\"Resampling Methods\"):\n",
    "    method_name = method.name.lower()\n",
    "    method_dir = os.path.join(main_dir, method_name)\n",
    "    os.makedirs(method_dir, exist_ok=True)\n",
    "\n",
    "    final_output_path = os.path.join(method_dir, f'UK_imputation_resampled_12km_{method_name}_processed.tif')\n",
    "\n",
    "    # Step 1: Resample raster2 to match the resolution of raster1 using the current method\n",
    "    with rasterio.open(raster1_path) as src_ref:\n",
    "        profile_ref = src_ref.profile\n",
    "        transform_ref = src_ref.transform\n",
    "\n",
    "    with rasterio.open(raster2_path) as src:\n",
    "        data = src.read(1)\n",
    "        resampled_data = np.empty(src_ref.shape, dtype=np.float32)\n",
    "        reproject(\n",
    "            source=rasterio.band(src, 1),\n",
    "            destination=resampled_data,\n",
    "            src_transform=src.transform,\n",
    "            src_crs=src.crs,\n",
    "            dst_transform=transform_ref,\n",
    "            dst_crs=profile_ref['crs'],\n",
    "            resampling=method\n",
    "        )\n",
    "\n",
    "    # Step 2: Process the resampled data to set zero values to NaN and save the final file\n",
    "    process_geotiff(resampled_data, profile_ref, final_output_path)\n",
    "    print(f\"The final raster with NaN values for zero data using {method_name} has been created and saved.\")\n",
    "\n",
    "    # Store the processed file path\n",
    "    processed_file_paths.append(final_output_path)\n",
    "\n",
    "# Print or use the list of processed file paths as needed\n",
    "print(\"List of all processed file paths:\")\n",
    "for path in processed_file_paths:\n",
    "    print(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing manual_method_resampling/nearest/UK_imputation_resampled_12km_nearest_processed.tif: 100%|██████████| 2446/2446 [00:00<00:00, 34843.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapefile saved successfully: manual_method_resampling/nearest/UK_imputation_resampled_12km_nearest_processed.shp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing manual_method_resampling/bilinear/UK_imputation_resampled_12km_bilinear_processed.tif: 100%|██████████| 2446/2446 [00:00<00:00, 42772.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapefile saved successfully: manual_method_resampling/bilinear/UK_imputation_resampled_12km_bilinear_processed.shp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing manual_method_resampling/cubic/UK_imputation_resampled_12km_cubic_processed.tif: 100%|██████████| 2446/2446 [00:00<00:00, 35226.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapefile saved successfully: manual_method_resampling/cubic/UK_imputation_resampled_12km_cubic_processed.shp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing manual_method_resampling/cubic_spline/UK_imputation_resampled_12km_cubic_spline_processed.tif: 100%|██████████| 2446/2446 [00:00<00:00, 38845.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapefile saved successfully: manual_method_resampling/cubic_spline/UK_imputation_resampled_12km_cubic_spline_processed.shp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing manual_method_resampling/lanczos/UK_imputation_resampled_12km_lanczos_processed.tif: 100%|██████████| 2204/2204 [00:00<00:00, 40065.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapefile saved successfully: manual_method_resampling/lanczos/UK_imputation_resampled_12km_lanczos_processed.shp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing manual_method_resampling/average/UK_imputation_resampled_12km_average_processed.tif: 100%|██████████| 3035/3035 [00:00<00:00, 31009.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapefile saved successfully: manual_method_resampling/average/UK_imputation_resampled_12km_average_processed.shp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing manual_method_resampling/mode/UK_imputation_resampled_12km_mode_processed.tif: 100%|██████████| 3035/3035 [00:00<00:00, 35694.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapefile saved successfully: manual_method_resampling/mode/UK_imputation_resampled_12km_mode_processed.shp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing manual_method_resampling/max/UK_imputation_resampled_12km_max_processed.tif: 100%|██████████| 3035/3035 [00:00<00:00, 34235.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapefile saved successfully: manual_method_resampling/max/UK_imputation_resampled_12km_max_processed.shp"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing manual_method_resampling/min/UK_imputation_resampled_12km_min_processed.tif: 100%|██████████| 3035/3035 [00:00<00:00, 40588.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapefile saved successfully: manual_method_resampling/min/UK_imputation_resampled_12km_min_processed.shp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing manual_method_resampling/med/UK_imputation_resampled_12km_med_processed.tif: 100%|██████████| 3035/3035 [00:00<00:00, 40450.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapefile saved successfully: manual_method_resampling/med/UK_imputation_resampled_12km_med_processed.shp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing manual_method_resampling/q1/UK_imputation_resampled_12km_q1_processed.tif: 100%|██████████| 3035/3035 [00:00<00:00, 32682.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapefile saved successfully: manual_method_resampling/q1/UK_imputation_resampled_12km_q1_processed.shp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing manual_method_resampling/q3/UK_imputation_resampled_12km_q3_processed.tif: 100%|██████████| 3035/3035 [00:00<00:00, 37355.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapefile saved successfully: manual_method_resampling/q3/UK_imputation_resampled_12km_q3_processed.shp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing manual_method_resampling/sum/UK_imputation_resampled_12km_sum_processed.tif: 100%|██████████| 3035/3035 [00:00<00:00, 33213.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapefile saved successfully: manual_method_resampling/sum/UK_imputation_resampled_12km_sum_processed.shp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing manual_method_resampling/rms/UK_imputation_resampled_12km_rms_processed.tif: 100%|██████████| 3035/3035 [00:00<00:00, 37669.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapefile saved successfully: manual_method_resampling/rms/UK_imputation_resampled_12km_rms_processed.shp\n",
      "New shapefile locations:\n",
      "manual_method_resampling/nearest/UK_imputation_resampled_12km_nearest_processed.shp\n",
      "manual_method_resampling/bilinear/UK_imputation_resampled_12km_bilinear_processed.shp\n",
      "manual_method_resampling/cubic/UK_imputation_resampled_12km_cubic_processed.shp\n",
      "manual_method_resampling/cubic_spline/UK_imputation_resampled_12km_cubic_spline_processed.shp\n",
      "manual_method_resampling/lanczos/UK_imputation_resampled_12km_lanczos_processed.shp\n",
      "manual_method_resampling/average/UK_imputation_resampled_12km_average_processed.shp\n",
      "manual_method_resampling/mode/UK_imputation_resampled_12km_mode_processed.shp\n",
      "manual_method_resampling/max/UK_imputation_resampled_12km_max_processed.shp\n",
      "manual_method_resampling/min/UK_imputation_resampled_12km_min_processed.shp\n",
      "manual_method_resampling/med/UK_imputation_resampled_12km_med_processed.shp\n",
      "manual_method_resampling/q1/UK_imputation_resampled_12km_q1_processed.shp\n",
      "manual_method_resampling/q3/UK_imputation_resampled_12km_q3_processed.shp\n",
      "manual_method_resampling/sum/UK_imputation_resampled_12km_sum_processed.shp\n",
      "manual_method_resampling/rms/UK_imputation_resampled_12km_rms_processed.shp\n"
     ]
    }
   ],
   "source": [
    "import rasterio\n",
    "from shapely.geometry import Point\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "# List of file locations\n",
    "file_locations = [\n",
    "    'manual_method_resampling/nearest/UK_imputation_resampled_12km_nearest_processed.tif',\n",
    "    'manual_method_resampling/bilinear/UK_imputation_resampled_12km_bilinear_processed.tif',\n",
    "    'manual_method_resampling/cubic/UK_imputation_resampled_12km_cubic_processed.tif',\n",
    "    'manual_method_resampling/cubic_spline/UK_imputation_resampled_12km_cubic_spline_processed.tif',\n",
    "    'manual_method_resampling/lanczos/UK_imputation_resampled_12km_lanczos_processed.tif',\n",
    "    'manual_method_resampling/average/UK_imputation_resampled_12km_average_processed.tif',\n",
    "    'manual_method_resampling/mode/UK_imputation_resampled_12km_mode_processed.tif',\n",
    "    'manual_method_resampling/max/UK_imputation_resampled_12km_max_processed.tif',\n",
    "    'manual_method_resampling/min/UK_imputation_resampled_12km_min_processed.tif',\n",
    "    'manual_method_resampling/med/UK_imputation_resampled_12km_med_processed.tif',\n",
    "    'manual_method_resampling/q1/UK_imputation_resampled_12km_q1_processed.tif',\n",
    "    'manual_method_resampling/q3/UK_imputation_resampled_12km_q3_processed.tif',\n",
    "    'manual_method_resampling/sum/UK_imputation_resampled_12km_sum_processed.tif',\n",
    "    'manual_method_resampling/rms/UK_imputation_resampled_12km_rms_processed.tif'\n",
    "]\n",
    "\n",
    "# List to store new shapefile locations\n",
    "new_shapefile_locations = []\n",
    "\n",
    "for input_file in file_locations:\n",
    "    # Open the GeoTIFF file\n",
    "    with rasterio.open(input_file) as src:\n",
    "        # Read the entire raster data into memory\n",
    "        data = src.read(1)\n",
    "        \n",
    "        # Get the nodata value\n",
    "        nodata_value = src.nodata\n",
    "\n",
    "        # Create a mask for valid data points (including zero values)\n",
    "        mask = (data != nodata_value) & ~np.isnan(data)\n",
    "        \n",
    "        # Get the row and column indices of valid data points\n",
    "        row_indices, col_indices = np.where(mask)\n",
    "        \n",
    "        # Get the pixel values of the valid data points\n",
    "        values = data[mask]\n",
    "        \n",
    "        # Initialize lists to store coordinates and values\n",
    "        lons, lats = [], []\n",
    "        \n",
    "        # Iterate with progress tracking\n",
    "        for row, col in tqdm(zip(row_indices, col_indices), total=len(row_indices), desc=f\"Processing {input_file}\"):\n",
    "            lon, lat = src.xy(row, col)\n",
    "            lons.append(lon)\n",
    "            lats.append(lat)\n",
    "\n",
    "    # Create a DataFrame from the valid points\n",
    "    df = pd.DataFrame({\n",
    "        'longitude': lons,\n",
    "        'latitude': lats,\n",
    "        'value': values\n",
    "    })\n",
    "\n",
    "    # Create a GeoDataFrame from the DataFrame\n",
    "    gdf = gpd.GeoDataFrame(df, geometry=gpd.points_from_xy(df.longitude, df.latitude), crs=src.crs)\n",
    "\n",
    "    # Define the output shapefile path\n",
    "    output_shapefile = input_file.replace('.tif', '.shp')\n",
    "\n",
    "    # Save the GeoDataFrame as a shapefile\n",
    "    gdf.to_file(output_shapefile)\n",
    "    \n",
    "    # Append the new shapefile location to the list\n",
    "    new_shapefile_locations.append(output_shapefile)\n",
    "\n",
    "    print(f\"Shapefile saved successfully: {output_shapefile}\")\n",
    "\n",
    "# Print the list of new shapefile locations\n",
    "print(\"New shapefile locations:\")\n",
    "for shapefile in new_shapefile_locations:\n",
    "    print(shapefile)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Idea 2 \n",
    "\n",
    "Convert whole data into points take the precipitation file within each big square store values and average by number of values there in that region."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert DEM to Points "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 1618746/1618746 [00:42<00:00, 38432.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapefile saved successfully: UK_DEM.shp\n"
     ]
    }
   ],
   "source": [
    "import rasterio\n",
    "from shapely.geometry import Point\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Path to your GeoTIFF file\n",
    "input_file = 'UK_DEM2.tif'\n",
    "\n",
    "# Open the GeoTIFF file\n",
    "with rasterio.open(input_file) as src:\n",
    "    # Read the entire raster data into memory\n",
    "    data = src.read(1)\n",
    "    \n",
    "    # Get the nodata value\n",
    "    nodata_value = src.nodata\n",
    "\n",
    "    # Create a mask for valid data points (including zero values)\n",
    "    mask = (data != nodata_value) & ~np.isnan(data)\n",
    "    \n",
    "    # Get the row and column indices of valid data points\n",
    "    row_indices, col_indices = np.where(mask)\n",
    "    \n",
    "    # Get the pixel values of the valid data points\n",
    "    values = data[mask]\n",
    "    \n",
    "    # Initialize lists to store coordinates and values\n",
    "    lons, lats = [], []\n",
    "    \n",
    "    # Iterate with progress tracking\n",
    "    for row, col in tqdm(zip(row_indices, col_indices), total=len(row_indices), desc=\"Processing\"):\n",
    "        lon, lat = src.xy(row, col)\n",
    "        lons.append(lon)\n",
    "        lats.append(lat)\n",
    "\n",
    "# Create a DataFrame from the valid points\n",
    "df = pd.DataFrame({\n",
    "    'longitude': lons,\n",
    "    'latitude': lats,\n",
    "    'value': values\n",
    "})\n",
    "\n",
    "# Create a GeoDataFrame from the DataFrame\n",
    "gdf = gpd.GeoDataFrame(df, geometry=gpd.points_from_xy(df.longitude, df.latitude), crs=src.crs)\n",
    "\n",
    "# Save the GeoDataFrame as a shapefile\n",
    "output_shapefile = 'UK_DEM.shp'\n",
    "gdf.to_file(output_shapefile)\n",
    "\n",
    "print(f\"Shapefile saved successfully: {output_shapefile}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting PPT data (raster) to Polygons (Vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 2502/2502 [00:00<00:00, 32559.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapefile saved successfully: UK_PPT_1980-2010.shp\n"
     ]
    }
   ],
   "source": [
    "import rasterio\n",
    "from shapely.geometry import Point, box\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Path to your GeoTIFF file\n",
    "input_file = 'ppt_1980-2010.tif'\n",
    "\n",
    "# Open the GeoTIFF file\n",
    "with rasterio.open(input_file) as src:\n",
    "    # Read the entire raster data into memory\n",
    "    data = src.read(1)\n",
    "    \n",
    "    # Get the nodata value\n",
    "    nodata_value = src.nodata\n",
    "\n",
    "    # Create a mask for valid data points (including zero values)\n",
    "    mask = (data != nodata_value) & ~np.isnan(data)\n",
    "    \n",
    "    # Get the row and column indices of valid data points\n",
    "    row_indices, col_indices = np.where(mask)\n",
    "    \n",
    "    # Get the pixel values of the valid data points\n",
    "    values = data[mask]\n",
    "    \n",
    "    # Initialize lists to store coordinates, values, and bounds\n",
    "    lons, lats, x_mins, y_mins, x_maxs, y_maxs = [], [], [], [], [], []\n",
    "    \n",
    "    # Get pixel size (resolution)\n",
    "    pixel_size_x, pixel_size_y = src.res\n",
    "    \n",
    "    # Iterate with progress tracking\n",
    "    for row, col in tqdm(zip(row_indices, col_indices), total=len(row_indices), desc=\"Processing\"):\n",
    "        lon, lat = src.xy(row, col)\n",
    "        lons.append(lon)\n",
    "        lats.append(lat)\n",
    "        x_min, y_min = lon - pixel_size_x / 2, lat - pixel_size_y / 2\n",
    "        x_max, y_max = lon + pixel_size_x / 2, lat + pixel_size_y / 2\n",
    "        x_mins.append(x_min)\n",
    "        y_mins.append(y_min)\n",
    "        x_maxs.append(x_max)\n",
    "        y_maxs.append(y_max)\n",
    "\n",
    "# Create a DataFrame from the valid points\n",
    "df = pd.DataFrame({\n",
    "    'longitude': lons,\n",
    "    'latitude': lats,\n",
    "    'value': values,\n",
    "    'x_min': x_mins,\n",
    "    'y_min': y_mins,\n",
    "    'x_max': x_maxs,\n",
    "    'y_max': y_maxs\n",
    "})\n",
    "\n",
    "# Create a GeoDataFrame from the DataFrame\n",
    "gdf = gpd.GeoDataFrame(df, geometry=[box(x_min, y_min, x_max, y_max) for x_min, y_min, x_max, y_max in zip(df.x_min, df.y_min, df.x_max, df.y_max)], crs=src.crs)\n",
    "\n",
    "# Save the GeoDataFrame as a shapefile\n",
    "output_shapefile = 'UK_PPT_1980-2010.shp'\n",
    "gdf.to_file(output_shapefile)\n",
    "\n",
    "print(f\"Shapefile saved successfully: {output_shapefile}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Polygons CRS: PROJCS[\"unnamed\",GEOGCS[\"unknown\",DATUM[\"D_unnamed\",SPHEROID[\"Spheroid\",6377563.396,299.324961266495]],PRIMEM[\"Greenwich\",0],UNIT[\"Degree\",0.0174532925199433]],PROJECTION[\"Transverse_Mercator\"],PARAMETER[\"latitude_of_origin\",49],PARAMETER[\"central_meridian\",-2],PARAMETER[\"scale_factor\",0.9996012717],PARAMETER[\"false_easting\",400000],PARAMETER[\"false_northing\",-100000],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH]]\n",
      "Points CRS: EPSG:4326\n",
      "Points reprojected to CRS: PROJCS[\"unnamed\",GEOGCS[\"unknown\",DATUM[\"D_unnamed\",SPHEROID[\"Spheroid\",6377563.396,299.324961266495]],PRIMEM[\"Greenwich\",0],UNIT[\"Degree\",0.0174532925199433]],PROJECTION[\"Transverse_Mercator\"],PARAMETER[\"latitude_of_origin\",49],PARAMETER[\"central_meridian\",-2],PARAMETER[\"scale_factor\",0.9996012717],PARAMETER[\"false_easting\",400000],PARAMETER[\"false_northing\",-100000],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing points: 100%|██████████| 1618746/1618746 [10:40<00:00, 2526.58it/s]\n",
      "C:\\Users\\vibhu\\AppData\\Local\\Temp\\ipykernel_1088\\4265153869.py:67: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
      "  gdf.to_file(output_shapefile_path)\n",
      "c:\\Users\\vibhu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pyogrio\\raw.py:709: RuntimeWarning: Normalized/laundered field name: 'average_dem' to 'average_de'\n",
      "  ogr_write(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated shapefile saved successfully: UK_DEM_12km.shp\n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "import rtree\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load the shapefile with polygons (bounding boxes)\n",
    "polygons_gdf = gpd.read_file('UK_PPT_1980-2010.shp')\n",
    "\n",
    "# Load the shapefile with points\n",
    "points_gdf = gpd.read_file('UK_DEM.shp')\n",
    "\n",
    "# Check the coordinate reference systems (CRS)\n",
    "print(f\"Polygons CRS: {polygons_gdf.crs}\")\n",
    "print(f\"Points CRS: {points_gdf.crs}\")\n",
    "\n",
    "# Ensure both GeoDataFrames have the same CRS\n",
    "if polygons_gdf.crs != points_gdf.crs:\n",
    "    points_gdf = points_gdf.to_crs(polygons_gdf.crs)\n",
    "    print(f\"Points reprojected to CRS: {points_gdf.crs}\")\n",
    "\n",
    "# Initialize fields in polygons GeoDataFrame\n",
    "polygons_gdf['val_dem'] = 0.0\n",
    "polygons_gdf['counter'] = 0\n",
    "\n",
    "# Create an R-tree index for the bounding boxes\n",
    "idx = rtree.index.Index()\n",
    "for poly_id, geometry in enumerate(polygons_gdf.geometry):\n",
    "    idx.insert(poly_id, geometry.bounds)\n",
    "\n",
    "# Iterate through each point with a progress bar\n",
    "for i, point in enumerate(tqdm(points_gdf.geometry, desc=\"Processing points\")):\n",
    "    # Get possible matching bounding boxes using the R-tree index\n",
    "    possible_matches_index = list(idx.intersection(point.bounds))\n",
    "    possible_matches = polygons_gdf.iloc[possible_matches_index]\n",
    "    \n",
    "    # Check if the point is actually within any of these polygons\n",
    "    for poly_id in possible_matches.index:\n",
    "        if possible_matches.loc[poly_id].geometry.contains(point):\n",
    "            # Update the val_dem and counter fields for the polygon\n",
    "            polygons_gdf.at[poly_id, 'val_dem'] += points_gdf.loc[i, 'value']  \n",
    "            polygons_gdf.at[poly_id, 'counter'] += 1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "gdf = polygons_gdf\n",
    "\n",
    "\n",
    "\n",
    "# Replace 'column1' and 'column2' with the names of your existing columns\n",
    "column1 = 'val_dem'\n",
    "column2 = 'counter'\n",
    "\n",
    "# Check if the columns exist\n",
    "if column1 not in gdf.columns or column2 not in gdf.columns:\n",
    "    raise ValueError(f\"One or both columns '{column1}' and '{column2}' do not exist in the shapefile.\")\n",
    "\n",
    "# Calculate the average of the two columns\n",
    "gdf['average_dem'] = (gdf[column1] / gdf[column2])\n",
    "\n",
    "# Print the first few rows to check the new column\n",
    "\n",
    "\n",
    "# Save the updated GeoDataFrame to a new shapefile\n",
    "output_shapefile_path = 'UK_DEM_12km.shp'\n",
    "gdf.to_file(output_shapefile_path)\n",
    "\n",
    "print(f\"Updated shapefile saved successfully: {output_shapefile_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing MSE of resampled and Average method\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average percentage differences saved successfully to average_percentage_differences.csv\n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# List of file locations\n",
    "shapefile_locations = [\n",
    "    'manual_method_resampling/nearest/UK_imputation_resampled_12km_nearest_processed.shp',\n",
    "    'manual_method_resampling/bilinear/UK_imputation_resampled_12km_bilinear_processed.shp',\n",
    "    'manual_method_resampling/cubic/UK_imputation_resampled_12km_cubic_processed.shp',\n",
    "    'manual_method_resampling/cubic_spline/UK_imputation_resampled_12km_cubic_spline_processed.shp',\n",
    "    'manual_method_resampling/lanczos/UK_imputation_resampled_12km_lanczos_processed.shp',\n",
    "    'manual_method_resampling/average/UK_imputation_resampled_12km_average_processed.shp',\n",
    "    'manual_method_resampling/mode/UK_imputation_resampled_12km_mode_processed.shp',\n",
    "    'manual_method_resampling/max/UK_imputation_resampled_12km_max_processed.shp',\n",
    "    'manual_method_resampling/min/UK_imputation_resampled_12km_min_processed.shp',\n",
    "    'manual_method_resampling/med/UK_imputation_resampled_12km_med_processed.shp',\n",
    "    'manual_method_resampling/q1/UK_imputation_resampled_12km_q1_processed.shp',\n",
    "    'manual_method_resampling/q3/UK_imputation_resampled_12km_q3_processed.shp',\n",
    "    'manual_method_resampling/sum/UK_imputation_resampled_12km_sum_processed.shp',\n",
    "    'manual_method_resampling/rms/UK_imputation_resampled_12km_rms_processed.shp'\n",
    "]\n",
    "\n",
    "# Read the reference shapefile\n",
    "reference_gdf = gpd.read_file('UK_DEM_12km.shp')\n",
    "reference_gdf = reference_gdf[['latitude', 'longitude', 'value']].rename(columns={'value': 'average_de'})\n",
    "\n",
    "# Initialize a list to hold the average percentage differences\n",
    "average_percentage_differences = []\n",
    "\n",
    "# Process each shapefile\n",
    "for shapefile in shapefile_locations:\n",
    "    # Read the shapefile\n",
    "    gdf = gpd.read_file(shapefile)\n",
    "    gdf = gdf[['latitude', 'longitude', 'value']].rename(columns={'value': 'value'})\n",
    "    \n",
    "    # Merge with the reference GeoDataFrame\n",
    "    merged_gdf = reference_gdf.merge(gdf, on=['latitude', 'longitude'], how='inner', suffixes=('_ref', '_comp'))\n",
    "    \n",
    "    # Calculate the percentage difference\n",
    "    merged_gdf['percentage_difference'] = (merged_gdf['average_de'] - merged_gdf['value']).abs() / merged_gdf['average_de'] \n",
    "    \n",
    "    # Calculate the average percentage difference\n",
    "    avg_percentage_difference = merged_gdf['percentage_difference'].mean()\n",
    "    \n",
    "    # Append the result to the list\n",
    "    average_percentage_differences.append({\n",
    "        'file': os.path.basename(shapefile),\n",
    "        'average_percentage_difference': avg_percentage_difference\n",
    "    })\n",
    "\n",
    "# Convert the results to a DataFrame\n",
    "avg_percentage_diff_df = pd.DataFrame(average_percentage_differences)\n",
    "\n",
    "# Save the results to a CSV file\n",
    "avg_percentage_diff_df.to_csv('average_percentage_differences.csv', index=False)\n",
    "\n",
    "print(\"Average percentage differences saved successfully to average_percentage_differences.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 file  \\\n",
      "0   UK_imputation_resampled_12km_nearest_processed...   \n",
      "1   UK_imputation_resampled_12km_bilinear_processe...   \n",
      "2    UK_imputation_resampled_12km_cubic_processed.shp   \n",
      "3   UK_imputation_resampled_12km_cubic_spline_proc...   \n",
      "4   UK_imputation_resampled_12km_lanczos_processed...   \n",
      "5   UK_imputation_resampled_12km_average_processed...   \n",
      "6     UK_imputation_resampled_12km_mode_processed.shp   \n",
      "7      UK_imputation_resampled_12km_max_processed.shp   \n",
      "8      UK_imputation_resampled_12km_min_processed.shp   \n",
      "9      UK_imputation_resampled_12km_med_processed.shp   \n",
      "10      UK_imputation_resampled_12km_q1_processed.shp   \n",
      "11      UK_imputation_resampled_12km_q3_processed.shp   \n",
      "12     UK_imputation_resampled_12km_sum_processed.shp   \n",
      "13     UK_imputation_resampled_12km_rms_processed.shp   \n",
      "\n",
      "    average_percentage_difference  \n",
      "0                       41.327182  \n",
      "1                       41.065341  \n",
      "2                       40.934714  \n",
      "3                       41.213734  \n",
      "4                       42.476105  \n",
      "5                       40.506084  \n",
      "6                       36.523262  \n",
      "7                       89.825935  \n",
      "8                       12.964330  \n",
      "9                       38.514879  \n",
      "10                      28.128961  \n",
      "11                      50.960001  \n",
      "12                   18440.349013  \n",
      "13                      44.089732  \n"
     ]
    }
   ],
   "source": [
    "print(avg_percentage_diff_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import rasterio\n",
    "from rasterio.transform import from_origin\n",
    "import numpy as np\n",
    "\n",
    "def vector_to_raster(vector_shapefile, reference_raster_file, output_raster_file, no_data_value=-9999):\n",
    "    \"\"\"\n",
    "    Converts vector data from a shapefile to raster format using a reference raster.\n",
    "\n",
    "    Parameters:\n",
    "    - vector_shapefile: path to the vector shapefile (with columns: longitude, latitude, value)\n",
    "    - reference_raster_file: path to the reference raster file\n",
    "    - output_raster_file: path for the output raster file\n",
    "    - no_data_value: value to represent no data in the raster\n",
    "    \"\"\"\n",
    "\n",
    "    # Load the vector data\n",
    "    vector_data = gpd.read_file(vector_shapefile)\n",
    "    if 'longitude' not in vector_data.columns or 'latitude' not in vector_data.columns or 'value' not in vector_data.columns:\n",
    "        raise ValueError(\"Shapefile must contain 'longitude', 'latitude', and 'value' columns.\")\n",
    "\n",
    "    # Open the reference raster\n",
    "    with rasterio.open(reference_raster_file) as ref_raster:\n",
    "        ref_transform = ref_raster.transform\n",
    "        ref_crs = ref_raster.crs\n",
    "        ref_width = ref_raster.width\n",
    "        ref_height = ref_raster.height\n",
    "        ref_pixel_size_x = ref_transform[0]\n",
    "        ref_pixel_size_y = -ref_transform[4]  # Pixel size in y-direction is negative in geotransform\n",
    "        ref_min_lon = ref_transform[2]\n",
    "        ref_max_lat = ref_transform[5]\n",
    "\n",
    "    # Create an empty raster array\n",
    "    raster_data = np.full((ref_height, ref_width), no_data_value, dtype=np.float32)\n",
    "\n",
    "    # Fill the raster data with values from vector data\n",
    "    for _, row in vector_data.iterrows():\n",
    "        lon = row['longitude']\n",
    "        lat = row['latitude']\n",
    "        value = row['average_de']\n",
    "        x_idx = int((lon - ref_min_lon) / ref_pixel_size_x)\n",
    "        y_idx = int((ref_max_lat - lat) / ref_pixel_size_y)\n",
    "        if 0 <= x_idx < ref_width and 0 <= y_idx < ref_height:\n",
    "            raster_data[y_idx, x_idx] = value\n",
    "\n",
    "    # Create the output raster file\n",
    "    with rasterio.open(\n",
    "        output_raster_file, 'w', driver='GTiff',\n",
    "        height=raster_data.shape[0], width=raster_data.shape[1],\n",
    "        count=1, dtype=raster_data.dtype,\n",
    "        crs=ref_crs, transform=ref_transform\n",
    "    ) as dst:\n",
    "        dst.write(raster_data, 1)\n",
    "        dst.write_mask(raster_data != no_data_value)  # Set no-data mask\n",
    "\n",
    "# Example usage\n",
    "vector_shapefile = 'UK_DEM_12km.shp'\n",
    "reference_raster_file = 'ppt_1980-2010.tif'\n",
    "output_raster_file = 'DEM_raster_12km.tif'\n",
    "\n",
    "vector_to_raster(vector_shapefile, reference_raster_file, output_raster_file)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
